{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cafcdea",
   "metadata": {},
   "source": [
    "# Push-Up Recognition using LSTM and Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e616f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Thư mục chứa ảnh đã chia nhãn\n",
    "DATASET_PATH = \"frame/\"\n",
    "LABELS = [\"push-down\", \"push-up\"]  # 0: Push-down, 1: Push-up\n",
    "\n",
    "# Khởi tạo Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def extract_keypoints(image):\n",
    "    \"\"\" Trích xuất keypoints từ ảnh sử dụng Mediapipe Pose \"\"\"\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.pose_landmarks:\n",
    "        keypoints = np.array([[lm.x, lm.y] for lm in results.pose_landmarks.landmark]).flatten()\n",
    "        return keypoints\n",
    "    return None\n",
    "\n",
    "def load_data():\n",
    "    \"\"\" Tải dữ liệu và trích xuất keypoints từ ảnh \"\"\"\n",
    "    X, y = [], []\n",
    "    for label, label_name in enumerate(LABELS):\n",
    "        folder = os.path.join(DATASET_PATH, str(label))\n",
    "        for file in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            keypoints = extract_keypoints(image)\n",
    "            if keypoints is not None:\n",
    "                X.append(keypoints)\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load dữ liệu\n",
    "X, y = load_data()\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(f\"Số lượng mẫu: {len(X)}, Số keypoints mỗi mẫu: {X.shape[1]}\")\n",
    "\n",
    "# Chia dữ liệu thành train và test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)\n",
    "\n",
    "# Chuyển nhãn thành dạng one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Reshape dữ liệu cho LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, activation=\"relu\", input_shape=(1, X_train.shape[2])),\n",
    "    LSTM(32, return_sequences=False, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile mô hình\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train mô hình\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(\"pushup_lstm_model.h5\")\n",
    "\n",
    "# Đánh giá mô hình\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Độ chính xác trên tập test: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Báo cáo phân loại\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))\n",
    "\n",
    "# Biểu đồ quá trình huấn luyện\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy over epochs\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
